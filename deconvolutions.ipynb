{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconvolutions\n",
    "\n",
    "Demonstration of deconvolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Direct convolution and back\n",
    "\n",
    "We can implement the convolution by flattening the kernel over the positions on the input. This yields a matrix of shape $(4,16)$ in the example. We then also have to flatten the input to get a shape of $(16,1)$. The dot product then has the shapes $(4,16)$ X $(16,1) = (4,1)$.\n",
    "Finally, the output has to be reshaped into shape $(2,2)$.\n",
    "\n",
    "The direct convolution:\n",
    "* Input size: $(4,4)$\n",
    "* Output size: $(2,2)$\n",
    "* Kernel size: $(3,3)$\n",
    "* Stride: $(1,1)$\n",
    "\n",
    "The corresponding transposed convolution:\n",
    "* Input size: $(2,2)$\n",
    "* Output size: $(4,4)$\n",
    "* Kernel size: $(3,3)$\n",
    "* Stride: $(1,1)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape direct convolution:  (4, 1)\n",
      "Output shape deconvolution / transposed convolution:  (16, 1)\n"
     ]
    }
   ],
   "source": [
    "# Transposing the matrix explicitly\n",
    "\n",
    "## =========================================================\n",
    "# Forward / convolution\n",
    "# Make input (4,4), flatten it to shape (16,1).\n",
    "x = np.ones([1,4,4,1])\n",
    "x = x.reshape(16,1)\n",
    "\n",
    "# Flatten the convolution operation. Stride (1,1) with the kernel (3,3) yields 4 positions.\n",
    "C = np.asarray([[1,1,1,0,1,1,1,0,1,1,1,0,0,0,0,0],\n",
    "                [0,1,1,1,0,1,1,1,0,1,1,1,0,0,0,0],\n",
    "                [0,0,0,0,1,1,1,0,1,1,1,0,1,1,1,0],\n",
    "                [0,0,0,0,0,1,1,1,0,1,1,1,0,1,1,1]\n",
    "                ])\n",
    "\n",
    "# Compute the output.\n",
    "y = np.dot(C, x)\n",
    "print(\"Output shape direct convolution: \", y.shape)\n",
    "\n",
    "## =========================================================\n",
    "# Backward / deconvolution, transposed convolution\n",
    "# Make input and flatten it to shape (4,1).\n",
    "x = np.asarray([[9,9],[9,9]])\n",
    "x = x.reshape(4,1)\n",
    "\n",
    "# Transpose the matrix C.\n",
    "\n",
    "C_t = C.transpose()\n",
    "# Compute the output.\n",
    "y = np.dot(C_t, x)\n",
    "print(\"Output shape deconvolution / transposed convolution: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can implement the same in tensorflow with `Conv2D` and `Conv2DTranspose`. We can set the kernel weights to 1 to replicate the example from above.\n",
    "\n",
    "Note that we need to provide a channel dimension and we also provide a batch dimension here.\n",
    "\n",
    "Looking at the values of the outputs we can see that they are the same as above. In the forward case the result is \n",
    "\n",
    "```\n",
    "[[9,9],\n",
    "[9,9]]\n",
    "```\n",
    "\n",
    "and in the backward case it is\n",
    "\n",
    "```\n",
    "[[9,18,18,9],\n",
    "[18,36,36,18],\n",
    "[18,36,36,18],\n",
    "[9,18,18,9]]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (1, 4, 4, 1)\n",
      "Output shape:  TensorShape([1, 2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# Direct convolution from (4,4) -> (2,2)\n",
    "\n",
    "# Make input.\n",
    "x = np.ones([1,4,4,1])\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float16)\n",
    "x = tf.reshape(x,[1,4,4,1]) # Add batch and channel dimension\n",
    "print(\"Input shape: \", x.shape)\n",
    "\n",
    "# Convolve.\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(1, (3,3), strides=(1,1), padding='valid', kernel_initializer='ones', use_bias=False)\n",
    "    ])\n",
    "y = model(x)\n",
    "\n",
    "tf.print(\"Output shape: \", y.shape)\n",
    "#print(y) # Uncomment to view the output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (1, 2, 2, 1)\n",
      "Output shape:  TensorShape([1, 4, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "# Deconvolution / Transposed convolution from (2,2) -> (4,4)\n",
    "\n",
    "# Make input.\n",
    "x = np.asarray([[9,9],[9,9]])\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float16)\n",
    "x = tf.reshape(x,[1,2,2,1])\n",
    "print(\"Input shape: \", x.shape)\n",
    "\n",
    "# Convolve\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2DTranspose(1,(3,3),strides=(1,1), padding='valid', kernel_initializer='ones', use_bias=False)\n",
    "])\n",
    "y = model(x)\n",
    "\n",
    "tf.print(\"Output shape: \", y.shape)\n",
    "#print(y) # Uncomment to view the output values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Deconvolution as convolution on padded input\n",
    "\n",
    "We can also implement the deconvolution from $(2,2) -> (4,4)$ by padding the input with $0s$ on the boarder up to shape $(6,6)$ and a direct convolution. That way, the model can still learn the upsampling as opposed to upsampling directly from $(2,2) -> (4,4)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (1, 2, 2, 1)\n",
      "Padded input shape:  (1, 6, 6, 1)\n",
      "Output shape:  TensorShape([1, 4, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "# Deconvolution as convolution with padded input\n",
    "\n",
    "# Make input.\n",
    "x = np.asarray([[9,9],[9,9]])\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float16)\n",
    "x = tf.reshape(x,[1,2,2,1])\n",
    "print(\"Input shape: \", x.shape)\n",
    "\n",
    "# Pad input with 0s.\n",
    "paddings = tf.constant([[0,0],[2,2],[2,2],[0,0]])\n",
    "x = tf.pad(x, paddings=paddings)\n",
    "print(\"Padded input shape: \", x.shape)\n",
    "\n",
    "# Convolve.\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(1, (3,3), strides=(1,1), padding='valid', kernel_initializer='ones', use_bias=False)\n",
    "])\n",
    "y = model(x)\n",
    "\n",
    "tf.print(\"Output shape: \", y.shape)\n",
    "#print(y) # Uncomment to view the output values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this yields the same result as in example 1 where we used `Conv2DTranspose`. We can also implement this by flattening the input and the kernel positions. However, since the matrix $C$ is of shape $(16,144)$ we won't write it out here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Fractionally strided convolution as direct convolution\n",
    "What if we want to go to a different output size, say $(2,2) -> (5,5)$? Here we can pad the input with 0s on the boarder as well as between elements, which transforms the input to shape $(7,7)$.\n",
    "\n",
    "This operation shows why a deconvolution is also called fractionally strided convolution. To move the kernel from one cell from the original input to its neighbour in the padded input, a stride of $2$ instead of $1$ is required. Thus a stride of $1$ corresponds to a stride of $1/2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded input shape:  (1, 7, 7, 1)\n",
      "Output shape:  TensorShape([1, 5, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "# Direct convolution plus padding between elements and on border\n",
    "\n",
    "# Make input, with padding between elements as well as on the border.\n",
    "x = np.asarray([[9,0,9],[0,0,0],[9,0,9]])\n",
    "x = x.reshape(1,3,3,1) # Add batch and channel dimension\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float16)\n",
    "paddings = tf.constant([[0,0],[2,2],[2,2],[0,0]])\n",
    "x = tf.pad(x, paddings=paddings)\n",
    "print(\"Padded input shape: \", x.shape)\n",
    "\n",
    "# Convolve.\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(1, (3,3), strides=(1,1), padding='valid', kernel_initializer='ones', use_bias=False)\n",
    "])\n",
    "\n",
    "y = model(x)\n",
    "tf.print(\"Output shape: \", y.shape)\n",
    "#print(y) # Uncomment to view the output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (1, 2, 2, 1)\n",
      "Output shape:  TensorShape([1, 5, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "# Transposed convolution\n",
    "x = np.asarray([[9,9],[9,9]])\n",
    "x = x.reshape(1,2,2,1)\n",
    "print(\"Input shape: \", x.shape)\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float16)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2DTranspose(1, (3,3), strides=(2,2), padding='valid', kernel_initializer='ones', use_bias=False)\n",
    "])\n",
    "\n",
    "y = model(x)\n",
    "tf.print(\"Output shape: \", y.shape)\n",
    "#print(y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52ee2977380704a66854748a73250e0671a9318bd5b3fd45a3df9f851ae61629"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
