{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconvolutions\n",
    "\n",
    "Demonstration of deconvolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: (4,4) -> (2,2) and back\n",
    "\n",
    "We can implement the convolution by flattening the kernel over the positions on the input. This yields a matrix of shape (4,16) in the example. We then also have to flatten the input to get a shape of (16,1). The dot product then has the shapes (4,16) x (16,1) = (4,1).\n",
    "Finally, the output has to be reshaped into shape (2,2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape forward pass/convolution:  (4, 1)\n",
      "Output shape backward pass/deconvolution:  (16, 1)\n"
     ]
    }
   ],
   "source": [
    "# Example 1.1\n",
    "#\n",
    "# Transposing the matrix explicitly\n",
    "#\n",
    "\n",
    "x = np.ones([1,4,4,1])\n",
    "x = x.reshape(16,1) # Flatten input to shape (16,1)\n",
    "\n",
    "# Flatten kernel on input. Stride (1,1) yields 4 positions.\n",
    "kernel = np.asarray([[1,1,1],[1,1,1],[1,1,1]])\n",
    "C = np.asarray([[1,1,1,0,1,1,1,0,1,1,1,0,0,0,0,0],\n",
    "                [0,1,1,1,0,1,1,1,0,1,1,1,0,0,0,0],\n",
    "                [0,0,0,0,1,1,1,0,1,1,1,0,1,1,1,0],\n",
    "                [0,0,0,0,0,1,1,1,0,1,1,1,0,1,1,1]\n",
    "                ])\n",
    "\n",
    "## =========================================================\n",
    "# Forward / convolution\n",
    "y = np.dot(C, x)\n",
    "print(\"Output shape forward pass/convolution: \", y.shape)\n",
    "\n",
    "## =========================================================\n",
    "# Backward / deconvolution, transposed convolution\n",
    "C_t = C.transpose()\n",
    "x = np.asarray([[9,9],[9,9]])\n",
    "x = x.reshape(4,1) # Flatten input\n",
    "\n",
    "y = np.dot(C_t, x)\n",
    "\n",
    "print(\"Output shape backward pass/deconvolution: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can implement the same in tensorflow with `Conv2D` and `Conv2DTranspose`. We can set the kernel weights to 1 to replicate the example from above.\n",
    "\n",
    "Note that we need to provide a channel dimension and we also provide a batch dimension here.\n",
    "\n",
    "Looking at the values of the outputs we can see that they are the same as above. In the forward case the result is \n",
    "\n",
    "```\n",
    "[[9,9],\n",
    "[9,9]]\n",
    "```\n",
    "\n",
    "and in the backward case it is\n",
    "\n",
    "```\n",
    "[[9,18,18,9],\n",
    "[18,36,36,18],\n",
    "[18,36,36,18],\n",
    "[9,18,18,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (1, 4, 4, 1)\n",
      "Output shape:  TensorShape([1, 2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# Example 1.2\n",
    "#\n",
    "# Convolution\n",
    "\n",
    "x = np.ones([1,4,4,1])\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "x = tf.reshape(x,[1,4,4,1])\n",
    "\n",
    "# Model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(1, (3,3), strides=(1,1), padding='valid', kernel_initializer='ones', use_bias=False)])\n",
    "\n",
    "print(\"Input shape: \", x.shape)\n",
    "y = model(x)\n",
    "tf.print(\"Output shape: \", y.shape)\n",
    "#print(y) # Uncomment to view the output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (1, 2, 2, 1)\n",
      "Output shape:  TensorShape([1, 4, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "# Example 1.3\n",
    "#\n",
    "# Deconvolution / Transposed convolution\n",
    "\n",
    "x = np.asarray([[9,9],[9,9]])\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "x = tf.reshape(x,[1,2,2,1])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2DTranspose(1,(3,3),strides=(1,1), padding='valid', kernel_initializer='ones', use_bias=False)\n",
    "])\n",
    "\n",
    "print(\"Input shape: \", x.shape)\n",
    "y = model(x)\n",
    "tf.print(\"Output shape: \", y.shape)\n",
    "#print(y) # Uncomment to view the output values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also implement the deconvolution with upsampling and a convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (1, 2, 2, 1)\n",
      "Output shape:  TensorShape([1, 4, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "# Deconvolution implemented with a convolution and padding. By using the conv layer the resizing can still be learned, despite the padding (upsampling).\n",
    "\n",
    "x = np.asarray([[9,9],[9,9]])\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32)\n",
    "x = tf.reshape(x,[1,2,2,1])\n",
    "print(\"Input shape: \", x.shape)\n",
    "\n",
    "# Pad input with 0s\n",
    "paddings = tf.constant([[0,0],[2,2],[2,2],[0,0]])\n",
    "x = tf.pad(x, paddings=paddings)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(1, (3,3), strides=(1,1), padding='valid', kernel_initializer='ones', use_bias=False)\n",
    "])\n",
    "\n",
    "y = model(x)\n",
    "tf.print(\"Output shape: \", y.shape)\n",
    "#print(y) # Uncomment to view the output values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: (5,5) -> (2,2) and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (1, 5, 5, 1)\n",
      "Output shape:  TensorShape([1, 2, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# Example 2\n",
    "# Stride (2,2) in input\n",
    "x = tf.ones([1,5,5,1])\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(1,(3,3), strides=(2,2), padding='valid')\n",
    "])\n",
    "\n",
    "print(\"Input shape: \", x.shape)\n",
    "y = model(x)\n",
    "tf.print(\"Output shape: \", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  (1, 6, 6, 1)\n",
      "Output shape:  TensorShape([1, 8, 8, 1])\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "# Example 2\n",
    "# Fractionally strided convolution\n",
    "x = tf.ones([1,2,2,1])\n",
    "\n",
    "# Pad input\n",
    "paddings = tf.constant([[0,0], [2,2], [2,2],[0,0]])\n",
    "x = tf.pad(x, paddings=paddings)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2DTranspose(1, (3,3), strides=(1,1), padding='valid')\n",
    "])\n",
    "\n",
    "print(\"Input shape: \", x.shape)\n",
    "y = model(x)\n",
    "tf.print(\"Output shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transposed convolution with a convolutional layer"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52ee2977380704a66854748a73250e0671a9318bd5b3fd45a3df9f851ae61629"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
